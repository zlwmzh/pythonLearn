#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2019/6/4 9:42
# @Author  : Aries
# @Site    : Micky
# @File    : 多项式线性回归.py
# @Software: PyCharm

"""
多项式线性回归:
功能：相当于将低维的空间上的数据映射到高纬空间中，相当于提取了更多的特征信息。
多项式扩展只是一种低纬度到高纬特征映射方式。
 -1. 首先对原始的特征数据做一个多项式扩展（原始特征属性合并产生新的特征属性）
 -2. 最后基于扩展之后的特征属性矩阵构建一个线性回归模型
 假设：
 原始数据如下（4个样本，每个样本2个特征属性x1、x2，一个目标属性y）：
 1 5  1
 2 8  2
 3 4  1
 5 9  3

 普通线性回归
 h(x) = theta0 + theta1 * x1 + theta2 * x2
 J(theta0, theta1, theta2) = (h(x_1) - y_1) ** 2 + (h(x_1) - y_1) ** 2 + (h(x_3) - y_3) ** 2
 + (h(x_4) - y_4) ** 2
 = (theta0 + theta1 * 1 + theta2 * 5 - 1) ** 2
 + (theta0 + theta1 * 2 + theta2 * 8 - 2) ** 2
 + (theta0 + theta1 * 3 + theta2 * 4 - 1) ** 2
 + (theta0 + theta1 * 5 + theta2 * 9 - 3) ** 2
 = 4 * theta0 ** 2 + (1 + 4 + 9 + 25) * theta1 ** 2 + (25 + 64 + 16 + 81) * theta2 ** 2 + ...



多项式线性回归
 -1. 做一个多项式扩展（2阶）：数据就变成了（四个样本，每个样本6个特征属性z1,z2,z3,z4,z5,z6,一个目标属性y）
  for d1 in range(0,3):
      for d2 in range(0,3):
      if d1+ d2 <= 2:
      :return x1 **(d1)x2 **(d2)
   d1   d2
   0     0
   0     1
   0     2
   1     0
   1     1
   1     2
   2     0
   2     1  （去掉）
   2     2 (去掉)
   可得：
   1 x1 x2 x1 * x2 x1 ** 2 x2 ** 2
带入假设数据：
1 1 5 5 1 25 1
1 2 8 18 4 64 2
1 3 4 12 9 16 1
1 5 9 45 25 81 3
   -2. 扩展之后的数据上做一个线性回归：
   h(x) = theta0 + theta1 * z1 + theta2 * z2+ theta3 * z3 + theta4 * z4+ theta5 * z5 + theta6 * z6




 (a + b ) ** 2 = a ** 2 + b ** 2 + 2 * a * b
 (a + b + c) ** 2 = (a + b) ** 2 + c ** 2 + 2 * (a + b) * c  =  a ** 2 + b ** 2 + 2 * a * b + c ** 2 + 2ac +2bc
 (a + b + c - d) ** 2 = a ** 2 + b ** 2 + c ** 2 + d ** 2 + 2ab + 2ac + 2bc - 2ad - 2bd -2cd
"""

"""
 -1. 熟悉sklearn的代码开发流程
 -2. KNN代码实现（可以运行的代码）
 -3. 理一下梯度下降的过程
"""
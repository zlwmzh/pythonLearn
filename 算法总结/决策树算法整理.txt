1. 决策树算法是什么？怎么理解决策树算法？
	决策树算法本质上就是if-else条件分支。通过概率的方式找到最好的分割方式。
2. 决策树构建过程是什么？决策树在选择划分特征属性的时候是如何选择的？为什么这样选择？
	a. 将特征属性看成一个个节点
	b. 遍历每个特征的分割方式，计算各种条件熵
	c. 遍历b步中的特征，找出条件熵最小的特征的分割方式，作为最优的划分方式
	d. 重复b、c步，知道划分的节点足够纯
3. ID3、C4.5、CART各种算法的区别和联系
	ID3算法以信息熵和信息增益做为纯度的衡量标准。每次迭代以信息增益最大的做为分割属性。ID3算法构建的是多叉树，只能处理离散性特征属性。只能用于分类
	C4.5算法是对ID3算法的优化，使用信息增益率取代信息增益，构建过程中增加了剪枝操作。C4.5算法构建的也是多叉树，只能处理离散性特征属性，只能用于分类
	CARTS算法使用GINI系数做为数据纯度衡量的标准。选择GINI增益率大的作为当前数据集的分割属性。CART算法构建的是二叉树，可用于分类和回归
   回归决策树预测值为连续值，而分类决策树的预测值为离散值。回归决策树的评估标准为MSE或者时MAE。而分类决策树
   可以通过概率的形式来表示他的纯度，如信息熵、条件熵、GINI系数等。
5. 回归决策树和线性回归模型的区别？
    线性回归模型是一种真实的连续值预测模型，而回归决策树模型则是以分段函数的形式预测连续值，其实是一种假设的连续值预测
6. 决策树的过拟合、欠拟合产生原因及解决方案
    当决策树的深度过大时就会产生过拟合，减小决策树的深度可以缓解过拟合
    当决策树的深度过浅时就会产生欠拟合，增大决策树的深度可以缓解欠拟合  
